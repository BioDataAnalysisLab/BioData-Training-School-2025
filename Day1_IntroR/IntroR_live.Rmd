---
title: "Intro to R and Data Handling - Live from 10 Dec"
author: "Brooke Wolford"
date: "2025-12-04"
output: html_document
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## License
This work is licensed under a Creative Commons Attribution–NonCommercial–ShareAlike 4.0 International License (CC BY-NC-SA 4.0). You are free to share and adapt the material for non-commercial purposes, as long as you give appropriate credit and distribute any derivative works under the same license. To view a copy of this license, visit: https://creativecommons.org/licenses/by-nc-sa/4.0/

# Part 1: Introduction to R

#### Sources
Content for this Module is derived from
* https://bookdown.org/rdpeng/rprogdatascience/r-nuts-and-bolts.html
* https://hbctraining.github.io/Intro-to-R-flipped/lessons/04_introR_packages.html
* https://swcarpentry.github.io/r-novice-inflammation/01-starting-with-data.html#manipulating-data

ChatGPT was used in the creation of examples and explanations.

### Objectives
By the end of this session, learners will be able to:
  * Basics of R programming
  * Understanding the RStudio IDE
  * RMarkdown for reproducible research

### R Markdown
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. 

A script ends in `.R` and a notebook ends in `.Rmd`

### Defining variables
R has five basic or “atomic” classes of objects:
  - character 
  - numeric (real numbers) 
  - integer 
  - complex 
  - logical (True/False) 

Once a variable is created, we can use the variable name to refer to the value it was assigned. The variable name now acts as a tag. To see the value of a variable, we can print it by:
  1) typing the name of the variable and hitting return in the Console
  2) if your cursor is on a line in the editor window, you can use control-enter (PC) or command-return (Mac)
  3) press the Run button above
  4) press the green play button in the RMarkdown code chunk
In general, R will print to the console any object returned by a function or operation unless we assign it to a variable.

```{r}

#we use an arrow to assign a value to a variable
x<-7

#we can coerce an object from one class to another
class(7)
class(x)
y<-as.integer(x)
class(y)

```

It is important that we name variables in a way that other users and our future selves will understand. Today, most R programmers 1) start variable names with lower case letters, 2) separate words in variable names with underscores, and 3) use only lowercase letters, underscores, and numbers in variable names. The [Tidyverse Style Guide](https://style.tidyverse.org/syntax.html) includes a section on this.

It's also important to use the `#` hash symbol to create comments for other users and our future selves.

The most basic type of R object is a vector. Vectors can only contain objects of the same class. A list is represented as a vector but can contain objects of different classes.

```{r}

#initialize a vector
a<-vector("numeric",10)
print(a)
class(a)
a

#define a vector with c() function
b<-c(1,2,3)
class(b)

#check what class the variables are


#create a data frame
x<-1:10
y<-rnorm(10)
df<-data.frame(x,y)
class(df)
dim(df)
nrow(df)
```


### Ways to use R
```{r} 

#as a calculator
1+2
sqrt(25)

# View summary statistics
heights <- c(150, 160, 165, 170, 155)
mean(heights)
median(heights)
summary(heights)

# plot data using base R
plot(heights)

# perform statistical tests
heights2<-c(100,80,85,90)


```


### Libraries and functions
Packages are collections of R functions, data, and compiled code in a well-defined format, created to add specific functionality. You can do a lot with base R, but there are 10,000+ user contributed packages on CRAN. The directories in R where the packages are stored are called the libraries.

In the R Console or when using R in Terminal, you can use the function `install.packages` to install a package. You can also use RStudio point-and-click functionality under the Packages tab. 

```{r}

#what libraries are loaded in the environment?
sessionInfo()

#now we call the package we installed
library(ggplot2)

#now we can use functions from the ggplot2 package
ggplot(df,aes(x,y)) + geom_point()

```


## Part 2: Data Handling in R

This lesson is based on content from Software Carpentry
* https://swcarpentry.github.io/r-novice-inflammation/01-starting-with-data.html
* https://datacarpentry.github.io/genomics-r-intro/05-dplyr.html
* https://datacarpentry.github.io/r-socialsci/03-dplyr.html
* https://datacarpentry.github.io/r-socialsci/04-tidyr.html
* https://mqwilber.github.io/2015-04-17-ucsb/lessons/intro_R_lessons/R_data_plotting_analysis.html

 ChatGPT was used in the creation of examples and explanations.

### Objectives

By the end of this session, learners will be able to:
  * Download data in Terminal to use in RStudio
  * Differentiate between data frames, lists, and matrices
  * Use base R to subset data
  * Use the dplyr package to manipulate dataframes.
  * Use select() to choose variables from a dataframe.
  * Use filter() to choose data based on values.
  * Use group_by() and summarize() to work with subsets of data.
  * Use mutate() to create new variables.

### Data frames, matrices, and lists

  * Data frame: most common tabular structure in R
  * List: collection of elements of different types
  * Matrix: 2D array of only one data type

```{r}

# Data frame
df <- data.frame(
  ID = 1:3,
  Name = c("Alice", "Bob", "Clara"),
  Age = c(34, 45, 29)
)

# List
patient <- list(
  ID = 101,
  Name = "David",
  Vitals = c(BP = 120, HR = 70),
  Notes = c("No allergies", "Nonsmoker")
)

# Matrix
mat <- matrix(1:9, nrow = 3, byrow = TRUE)

# Explore structure
str(df)
str(patient)
str(mat)
```


### Set-up our environment

The tidyverse package is an "umbrella-package" that installs several packages useful for data analysis which work together well such as tidyr, dplyr, readr, ggplot2, etc. It can take some time to install, so do that later if you would like. The Setup.R script you ran earlier should have installed these packages for you. If not, you may need to use the example `install.packages()` command below.

```{r}
library(dplyr)
library(tidyr)
library(readr)

#library(tidyverse)
#install.packages("dplyr")
```

### Read in data

We are going to use example data from Software Carpentry. I have already downloaded it and included it in the directory where this code is. If the directory with this code is showing in the Files pane in the bottom right, you can click on the More and select "Copy Folder Path to Clipboard." Paste that path below where it says "PASTE HERE". Be sure to keep the quotations and remove the hashtag.

```{r}
#MAC
#copy folder path to clipboard
path<-"~/Documents/MyStuff/Misc/Coding/GitHub/BioData-Training-School-2025/Day1_IntroR"
file<-"/sample.csv"
path<-paste0(path,file)
dat<-read_csv(file=path,col_names=FALSE)

#Windows 
#Set As working directory
path<-""
file<-"sample.csv"
path<-paste0(path,file)
dat<-read_csv(file=path,col_names=FALSE)

```

Now, let's read our data into R. There are several options for reading csv files:

- Base R has the function `read.csv()` which creates a basic data frame.
- I like to use the `data.table` package which has a function `fread()` and can be memory efficient for reading larger datasets. This creates a data.table object which has its own grammar for manipulating.
- The tidyverse has the `readr` package with the function `read_csv()`. This creates a tibble, a special type of data frame.


```{r}

#we pass 2 arguments, the path where the file is, and information about if the file has column names
#we assign the data frame information to the variable "dat"
dat<-read_csv(file=path,col_names=FALSE)
dat<-read_csv(file="sample.csv",col_names=FALSE)
	#for local access from Windows computers (given that the working directory is set to "../BioData-Training-School-2025/Day1_IntroR") 
		#NB: Cannot use file paths with the read_csv command on Windows, so working directory needs to be set beforehand
	#dat<-read_csv(file, col_names=FALSE)

#let's look at the first few rows 
head(dat)

```

Using `head` we see that R has auto-generated column names in the sequence V1 (for “variable 1”), V2, and so on. Why do you think that happened? What do you think the `col_names` option does? How can we find out? What is the default parameter for col_names? Note, if you are using base R and the `read.csv` function, the relevant option is `header`.

```{r}

#let's inspect the function details


#what about the baseR function


#let's read in the file with base R and read in the header properly now
dat<-read_csv(file="sample.csv",col_names=TRUE)
head(dat)
dat<-read_csv(file="sample.csv")

#let's use base R because it's a little easier for beginners

	#for local access from Windows computers (given that the working directory is set to "HealthAIinR/data") 
		#NB: Cannot use file paths with the read.csv command on Windows, so working directory needs to be set beforehand
	#dat<-read.csv(file, header=TRUE)

```

### Exploring the data with base R

We are going to start digging into the data with base R. There are several functions that help us inspect our data to get a sense of what it looks like.

```{r}

```

Each row holds the observations for just one patient. Each column holds values for several variables such as gender, blood pressure, and age.

For every column in the data frame, the function `summary` calculates: the minimum value, the first quartile, the median, the mean, the third quartile and the max value, giving helpful details about the sample distribution.
Like many programming languages, we can use indices to specify a certain row and column. The first value in brackets is row, and the second is column. R starts indices at 1, but some other languages use 0, so be mindful of this.

If we want to select more than one row or column, we can use the function c, which combines the values you give it into one vector or list.

If we want to select contiguous rows or columns, we can use the colon.

```{r}

#this will pull out the value in the 30th row and 20th column

#let's check what 1:5 does

#now let's use it in row and column space


```

If we leave the row or column space open, it means we want to select all of that row or column.

```{r}

#All columns from row 3 to see the values for Sub003


# All rows from column 6-9 regarding Anuerysms


#what do you think happens if we leave both values empty


```

We can also use column names. This is helpful because if you add columns or rows later, the indices could change.

```{r}

#using the $ operator 
dat$BloodPressure
class(dat$BloodPressure)
#dat[r,c]
dat[,"BloodPressure"]
class(dat[,"BloodPressure"])

#Name within square brackets

#rows can have names too; in this case they're just the row index
dat["1",]
dat[1,]

```

All the indexing and subsetting that works on data frames also works on vectors.

```{r}

#pull out a column from the data frame as a vector
BP_vec<-dat$BloodPressure

#subset for the first 10 participants
1:10
BP_vec[1:10]

```

### Enter the tidyverse: dplyr and tidyr

Common dplyr verbs: `filter`, `select`, `mutate`, `summarize`, `group_by`
Check out the [dplyr cheatsheet](https://rstudio.github.io/cheatsheets/data-transformation.pdf)

Note: The packages in the tidyverse, namely dplyr, tidyr and ggplot2 accept both the British (e.g. summarise) and American (e.g. summarize) spelling variants of different function and option names.

### `filter()` and `select()`

```{r}

#functionality similar to str()
str(dat)
glimpse(dat)

#in dplyr we can select the columns by name
select(dat,Age)

#another way to do this is with the pipe
dat %>% select(Age)

# we can use filter to filter observations for individuals with high blood pressure, this time let's save it into a new data frame
high <- dat %>% filter(BloodPressure>130)

# what object class is high
class(high)

```

You may also have noticed that the output from the object `high` doesn’t run off the screen anymore. It’s one of the advantages of tbl_df (also called tibble), the central data class in the tidyverse, compared to normal dataframes in R.

```{r}
#you can see we went from 100 to 30 observations when we used filter()
nrow(dat)
nrow(high)

# We can also specify multiple conditions within the filter() function.

#high blood pressure and the control group
high_control<-dat %>% filter(BloodPressure>130,Group=="Control")

# To form “and” statements within dplyr, we can pass our desired conditions as arguments in the filter() function, separated by commas:
high_control<-dat %>% filter(BloodPressure>130 & Group=="Control")

# or we can use the ampersand "&" operator


#how can we check that both of these filtered data frames are the same size?

# Have you noticed that the Gender column uses two conventions for male/female (lower case and upper case)?
table(dat$Gender)
dat %>% count(Gender)


# To filter for the male participants, we will need to accomodate both conventions

# For an “or” statement, observations must meet at least one of the specified conditions. To form “or” statements we use the logical operator for “or,” which is the vertical bar (|):
males <- dat %>% filter(Gender=="M"|Gender=="m")
males %>% count(Gender)

```

### Pipes

What if we want to select and filter at the same time?

With intermediate steps, you create a temporary dataframe and use that as input to the next function.
You can also use nested functions (one function inside of another). R will evaluate the expression from the inside out.

Pipes let you take the output of one function and send it directly to the next, which is useful when you need to do many things to the same dataset. 

There are two Pipes in R: 
1) %>% (called magrittr pipe; made available via the magrittr package, installed automatically with dplyr)
2) |> (called native R pipe and it comes preinstalled with R v4.1.0 onwards). 
Both the pipes are, by and large, function similarly with a few differences.

Some may find it helpful to read the pipe like the word “then”. 

```{r}

#combining filter and select with a pipe
high_control_males<- dat %>% filter(Gender=="M"|Gender=="m")  %>% 
  filter(BloodPressure>130 & Group=="Control")

dat %>% filter(BloodPressure>130) %>% select(Age)

```

### `mutate()`

Frequently you’ll want to create new columns based on the values in existing columns, and for this you can use `mutate()`.

```{r}

#Let's fix the mismatched upper and lower case
dat<-dat %>% mutate(Gender_v2=toupper(Gender))

dat %>% count(Gender)
dat %>% count(Gender_v2)

# Is the new column there?


# We have to save this back to the "dat" object so the new column will be represented in future versions of the tibble


```


### `group_by()` and `summarize()`

Many data analysis tasks can be approached using the split-apply-combine paradigm: split the data into groups, apply some analysis to each group, and then combine the results. dplyr makes this very easy through the use of the `group_by()` function. `group_by()` is often used together with `summarize()`, which collapses each group into a single-row summary of that group.

```{r}

# What is the median blood pressure per treatment group?
dat %>% group_by(Group) %>% 
  summarize(medianBP_group=median(BloodPressure))

# Can we also stratify by sex?
dat %>% 
  group_by(Group,Gender_v2) %>%
  summarize(medianBP_group=median(BloodPressure))


```

### `count()`

```{r}

#how many of each treatment group are there?


#let's sort by size


```

### long and wide data

A lot of data you will encounter is in a long format:
1) each column is a variable
2) each row is an observation
3) each value has its own cell
Long format is more machine readable and is closer to the formatting of databases.

Alternatively, in a “wide” data format we see modifications to rule 1, where each column no longer represents a single variable. Instead, columns can represent different levels/values of a variable. 

The columns Aneurisms_q1-Aneurisms_q4 are total number of aneurysms for both eyes in four different quadrants of the eye. We can think of this part of the data frame as being rather wide. If we wanted it to be longer, we would have just 2 columns, one being the quadrant number and one being the number of aneurysms in the quadrant. 

Two key functions in `tidyr` are `pivot_longer()` and `pivot_wider()`. [tidyr cheatsheet](https://rstudio.github.io/cheatsheets/tidyr.pdf)

`pivot_longer()` takes four principal arguments:

1) the data
2) cols are the names of the columns we use to fill the a new values variable (or to drop).
3) the names_to column variable we wish to create from the cols provided.
4) the values_to column variable we wish to create and fill with values associated with the cols provided.

```{r}

#create new dataset called long
long<-dat %>% pivot_longer(cols=Aneurisms_q1:Aneurisms_q4,names_to="Quadrant",values_to="AneurismsCount")

# what do you observe about the new data frame?

# now we can use group_by to summarize by quadrant, this would have been difficult in the previous format


```

We can think of the Group and BloodPressure columns of the dataset as being a long version of something that could be represented with a wide format. Let's test `pivot_wider` here.

`pivot_wider()` takes three principal arguments:

1) the data
2) the names_from column variable whose values will become new column names.
3) the values_from column variable whose values will fill the new column variables.

Further arguments include values_fill which, if set, fills in missing values with the value provided.

```{r}

#use pivot wider

# You see we have NA in the cells that are missing. This probably isn't a good data format for this dataset, but it may come in handy in other scenarios.

```

# Challenge

Task: Given a simple data frame of patients with ID, sex, age, and cholesterol values in two visits, write code to:
	1.	Filter patients over 45 years and save to a new dataset called sub, how many are there?
	2.  Select ID, Sex, and Cholesterol columns to a new dataset called sub2.
	3.	Using sub2, create a new variable that is 1 if the patient has high cholesterol (over 200), and 0 otherwise. Save this to a datset called high.
	4.	Using sub2, summarize average cholesterol by sex

```{r}

df <- data.frame(
  ID = 1:8,
  Age = c(34, 60, 45, 50, 29, 80, 55, 65),
  SBP = c(120, 140, 135, 150, 110, 140, 120, 125 ),
  cholesterol = c(200,220, 190, 195, 180, 240, 230, 235),
  sex = c("Male","Male","Female","Male","Female","Female","Male","Male")
)

# Filter patients over 45 and save to a new dataset named sub


# How many patients are over 45?

# In the original dataset, select the ID, sex, and cholesterol column for a new dataset


# Create a new variable (indicator variable) showing whether cholesterol is above 200


# Summarize average cholesterol by sex

```

